{"format": "torch", "nodes": [{"name": "rpn", "id": 139949741075312, "class_name": "RPN(\n  (backbone_net): Pointnet2MSG(\n    (SA_modules): ModuleList(\n      (0): PointnetSAModuleMSG(\n        (groupers): ModuleList(\n          (0): QueryAndGroup()\n          (1): QueryAndGroup()\n        )\n        (mlps): ModuleList(\n          (0): SharedMLP(\n            (layer0): Conv2d(\n              (conv): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n            (layer1): Conv2d(\n              (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n            (layer2): Conv2d(\n              (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n          )\n          (1): SharedMLP(\n            (layer0): Conv2d(\n              (conv): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n            (layer1): Conv2d(\n              (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n            (layer2): Conv2d(\n              (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n          )\n        )\n      )\n      (1): PointnetSAModuleMSG(\n        (groupers): ModuleList(\n          (0): QueryAndGroup()\n          (1): QueryAndGroup()\n        )\n        (mlps): ModuleList(\n          (0): SharedMLP(\n            (layer0): Conv2d(\n              (conv): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n            (layer1): Conv2d(\n              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n            (layer2): Conv2d(\n              (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n          )\n          (1): SharedMLP(\n            (layer0): Conv2d(\n              (conv): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n            (layer1): Conv2d(\n              (conv): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n            (layer2): Conv2d(\n              (conv): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n          )\n        )\n      )\n      (2): PointnetSAModuleMSG(\n        (groupers): ModuleList(\n          (0): QueryAndGroup()\n          (1): QueryAndGroup()\n        )\n        (mlps): ModuleList(\n          (0): SharedMLP(\n            (layer0): Conv2d(\n              (conv): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n            (layer1): Conv2d(\n              (conv): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n            (layer2): Conv2d(\n              (conv): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n          )\n          (1): SharedMLP(\n            (layer0): Conv2d(\n              (conv): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n            (layer1): Conv2d(\n              (conv): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n            (layer2): Conv2d(\n              (conv): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n          )\n        )\n      )\n      (3): PointnetSAModuleMSG(\n        (groupers): ModuleList(\n          (0): QueryAndGroup()\n          (1): QueryAndGroup()\n        )\n        (mlps): ModuleList(\n          (0): SharedMLP(\n            (layer0): Conv2d(\n              (conv): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n            (layer1): Conv2d(\n              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n            (layer2): Conv2d(\n              (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n          )\n          (1): SharedMLP(\n            (layer0): Conv2d(\n              (conv): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n            (layer1): Conv2d(\n              (conv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n            (layer2): Conv2d(\n              (conv): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (bn): BatchNorm2d(\n                (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              )\n              (activation): ReLU(inplace)\n            )\n          )\n        )\n      )\n    )\n    (FP_modules): ModuleList(\n      (0): PointnetFPModule(\n        (mlp): SharedMLP(\n          (layer0): Conv2d(\n            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (activation): ReLU(inplace)\n          )\n          (layer1): Conv2d(\n            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(\n              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (activation): ReLU(inplace)\n          )\n        )\n      )\n      (1): PointnetFPModule(\n        (mlp): SharedMLP(\n          (layer0): Conv2d(\n            (conv): Conv2d(608, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (activation): ReLU(inplace)\n          )\n          (layer1): Conv2d(\n            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(\n              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (activation): ReLU(inplace)\n          )\n        )\n      )\n      (2): PointnetFPModule(\n        (mlp): SharedMLP(\n          (layer0): Conv2d(\n            (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (activation): ReLU(inplace)\n          )\n          (layer1): Conv2d(\n            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (activation): ReLU(inplace)\n          )\n        )\n      )\n      (3): PointnetFPModule(\n        (mlp): SharedMLP(\n          (layer0): Conv2d(\n            (conv): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (activation): ReLU(inplace)\n          )\n          (layer1): Conv2d(\n            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (bn): BatchNorm2d(\n              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            )\n            (activation): ReLU(inplace)\n          )\n        )\n      )\n    )\n  )\n  (rpn_cls_layer): Sequential(\n    (0): Conv1d(\n      (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n      (bn): BatchNorm1d(\n        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (activation): ReLU(inplace)\n    )\n    (1): Dropout(p=0.5)\n    (2): Conv1d(\n      (conv): Conv1d(128, 1, kernel_size=(1,), stride=(1,))\n    )\n  )\n  (rpn_reg_layer): Sequential(\n    (0): Conv1d(\n      (conv): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n      (bn): BatchNorm1d(\n        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (activation): ReLU(inplace)\n    )\n    (1): Dropout(p=0.5)\n    (2): Conv1d(\n      (conv): Conv1d(128, 76, kernel_size=(1,), stride=(1,))\n    )\n  )\n  (rpn_cls_loss_func): SigmoidFocalClassificationLoss()\n  (proposal_layer): ProposalLayer()\n)", "parameters": [["backbone_net.SA_modules.0.mlps.0.layer0.conv.weight", [16, 3, 1, 1]], ["backbone_net.SA_modules.0.mlps.0.layer0.bn.bn.weight", [16]], ["backbone_net.SA_modules.0.mlps.0.layer0.bn.bn.bias", [16]], ["backbone_net.SA_modules.0.mlps.0.layer1.conv.weight", [16, 16, 1, 1]], ["backbone_net.SA_modules.0.mlps.0.layer1.bn.bn.weight", [16]], ["backbone_net.SA_modules.0.mlps.0.layer1.bn.bn.bias", [16]], ["backbone_net.SA_modules.0.mlps.0.layer2.conv.weight", [32, 16, 1, 1]], ["backbone_net.SA_modules.0.mlps.0.layer2.bn.bn.weight", [32]], ["backbone_net.SA_modules.0.mlps.0.layer2.bn.bn.bias", [32]], ["backbone_net.SA_modules.0.mlps.1.layer0.conv.weight", [32, 3, 1, 1]], ["backbone_net.SA_modules.0.mlps.1.layer0.bn.bn.weight", [32]], ["backbone_net.SA_modules.0.mlps.1.layer0.bn.bn.bias", [32]], ["backbone_net.SA_modules.0.mlps.1.layer1.conv.weight", [32, 32, 1, 1]], ["backbone_net.SA_modules.0.mlps.1.layer1.bn.bn.weight", [32]], ["backbone_net.SA_modules.0.mlps.1.layer1.bn.bn.bias", [32]], ["backbone_net.SA_modules.0.mlps.1.layer2.conv.weight", [64, 32, 1, 1]], ["backbone_net.SA_modules.0.mlps.1.layer2.bn.bn.weight", [64]], ["backbone_net.SA_modules.0.mlps.1.layer2.bn.bn.bias", [64]], ["backbone_net.SA_modules.1.mlps.0.layer0.conv.weight", [64, 99, 1, 1]], ["backbone_net.SA_modules.1.mlps.0.layer0.bn.bn.weight", [64]], ["backbone_net.SA_modules.1.mlps.0.layer0.bn.bn.bias", [64]], ["backbone_net.SA_modules.1.mlps.0.layer1.conv.weight", [64, 64, 1, 1]], ["backbone_net.SA_modules.1.mlps.0.layer1.bn.bn.weight", [64]], ["backbone_net.SA_modules.1.mlps.0.layer1.bn.bn.bias", [64]], ["backbone_net.SA_modules.1.mlps.0.layer2.conv.weight", [128, 64, 1, 1]], ["backbone_net.SA_modules.1.mlps.0.layer2.bn.bn.weight", [128]], ["backbone_net.SA_modules.1.mlps.0.layer2.bn.bn.bias", [128]], ["backbone_net.SA_modules.1.mlps.1.layer0.conv.weight", [64, 99, 1, 1]], ["backbone_net.SA_modules.1.mlps.1.layer0.bn.bn.weight", [64]], ["backbone_net.SA_modules.1.mlps.1.layer0.bn.bn.bias", [64]], ["backbone_net.SA_modules.1.mlps.1.layer1.conv.weight", [96, 64, 1, 1]], ["backbone_net.SA_modules.1.mlps.1.layer1.bn.bn.weight", [96]], ["backbone_net.SA_modules.1.mlps.1.layer1.bn.bn.bias", [96]], ["backbone_net.SA_modules.1.mlps.1.layer2.conv.weight", [128, 96, 1, 1]], ["backbone_net.SA_modules.1.mlps.1.layer2.bn.bn.weight", [128]], ["backbone_net.SA_modules.1.mlps.1.layer2.bn.bn.bias", [128]], ["backbone_net.SA_modules.2.mlps.0.layer0.conv.weight", [128, 259, 1, 1]], ["backbone_net.SA_modules.2.mlps.0.layer0.bn.bn.weight", [128]], ["backbone_net.SA_modules.2.mlps.0.layer0.bn.bn.bias", [128]], ["backbone_net.SA_modules.2.mlps.0.layer1.conv.weight", [196, 128, 1, 1]], ["backbone_net.SA_modules.2.mlps.0.layer1.bn.bn.weight", [196]], ["backbone_net.SA_modules.2.mlps.0.layer1.bn.bn.bias", [196]], ["backbone_net.SA_modules.2.mlps.0.layer2.conv.weight", [256, 196, 1, 1]], ["backbone_net.SA_modules.2.mlps.0.layer2.bn.bn.weight", [256]], ["backbone_net.SA_modules.2.mlps.0.layer2.bn.bn.bias", [256]], ["backbone_net.SA_modules.2.mlps.1.layer0.conv.weight", [128, 259, 1, 1]], ["backbone_net.SA_modules.2.mlps.1.layer0.bn.bn.weight", [128]], ["backbone_net.SA_modules.2.mlps.1.layer0.bn.bn.bias", [128]], ["backbone_net.SA_modules.2.mlps.1.layer1.conv.weight", [196, 128, 1, 1]], ["backbone_net.SA_modules.2.mlps.1.layer1.bn.bn.weight", [196]], ["backbone_net.SA_modules.2.mlps.1.layer1.bn.bn.bias", [196]], ["backbone_net.SA_modules.2.mlps.1.layer2.conv.weight", [256, 196, 1, 1]], ["backbone_net.SA_modules.2.mlps.1.layer2.bn.bn.weight", [256]], ["backbone_net.SA_modules.2.mlps.1.layer2.bn.bn.bias", [256]], ["backbone_net.SA_modules.3.mlps.0.layer0.conv.weight", [256, 515, 1, 1]], ["backbone_net.SA_modules.3.mlps.0.layer0.bn.bn.weight", [256]], ["backbone_net.SA_modules.3.mlps.0.layer0.bn.bn.bias", [256]], ["backbone_net.SA_modules.3.mlps.0.layer1.conv.weight", [256, 256, 1, 1]], ["backbone_net.SA_modules.3.mlps.0.layer1.bn.bn.weight", [256]], ["backbone_net.SA_modules.3.mlps.0.layer1.bn.bn.bias", [256]], ["backbone_net.SA_modules.3.mlps.0.layer2.conv.weight", [512, 256, 1, 1]], ["backbone_net.SA_modules.3.mlps.0.layer2.bn.bn.weight", [512]], ["backbone_net.SA_modules.3.mlps.0.layer2.bn.bn.bias", [512]], ["backbone_net.SA_modules.3.mlps.1.layer0.conv.weight", [256, 515, 1, 1]], ["backbone_net.SA_modules.3.mlps.1.layer0.bn.bn.weight", [256]], ["backbone_net.SA_modules.3.mlps.1.layer0.bn.bn.bias", [256]], ["backbone_net.SA_modules.3.mlps.1.layer1.conv.weight", [384, 256, 1, 1]], ["backbone_net.SA_modules.3.mlps.1.layer1.bn.bn.weight", [384]], ["backbone_net.SA_modules.3.mlps.1.layer1.bn.bn.bias", [384]], ["backbone_net.SA_modules.3.mlps.1.layer2.conv.weight", [512, 384, 1, 1]], ["backbone_net.SA_modules.3.mlps.1.layer2.bn.bn.weight", [512]], ["backbone_net.SA_modules.3.mlps.1.layer2.bn.bn.bias", [512]], ["backbone_net.FP_modules.0.mlp.layer0.conv.weight", [128, 256, 1, 1]], ["backbone_net.FP_modules.0.mlp.layer0.bn.bn.weight", [128]], ["backbone_net.FP_modules.0.mlp.layer0.bn.bn.bias", [128]], ["backbone_net.FP_modules.0.mlp.layer1.conv.weight", [128, 128, 1, 1]], ["backbone_net.FP_modules.0.mlp.layer1.bn.bn.weight", [128]], ["backbone_net.FP_modules.0.mlp.layer1.bn.bn.bias", [128]], ["backbone_net.FP_modules.1.mlp.layer0.conv.weight", [256, 608, 1, 1]], ["backbone_net.FP_modules.1.mlp.layer0.bn.bn.weight", [256]], ["backbone_net.FP_modules.1.mlp.layer0.bn.bn.bias", [256]], ["backbone_net.FP_modules.1.mlp.layer1.conv.weight", [256, 256, 1, 1]], ["backbone_net.FP_modules.1.mlp.layer1.bn.bn.weight", [256]], ["backbone_net.FP_modules.1.mlp.layer1.bn.bn.bias", [256]], ["backbone_net.FP_modules.2.mlp.layer0.conv.weight", [512, 768, 1, 1]], ["backbone_net.FP_modules.2.mlp.layer0.bn.bn.weight", [512]], ["backbone_net.FP_modules.2.mlp.layer0.bn.bn.bias", [512]], ["backbone_net.FP_modules.2.mlp.layer1.conv.weight", [512, 512, 1, 1]], ["backbone_net.FP_modules.2.mlp.layer1.bn.bn.weight", [512]], ["backbone_net.FP_modules.2.mlp.layer1.bn.bn.bias", [512]], ["backbone_net.FP_modules.3.mlp.layer0.conv.weight", [512, 1536, 1, 1]], ["backbone_net.FP_modules.3.mlp.layer0.bn.bn.weight", [512]], ["backbone_net.FP_modules.3.mlp.layer0.bn.bn.bias", [512]], ["backbone_net.FP_modules.3.mlp.layer1.conv.weight", [512, 512, 1, 1]], ["backbone_net.FP_modules.3.mlp.layer1.bn.bn.weight", [512]], ["backbone_net.FP_modules.3.mlp.layer1.bn.bn.bias", [512]], ["rpn_cls_layer.0.conv.weight", [128, 128, 1]], ["rpn_cls_layer.0.bn.bn.weight", [128]], ["rpn_cls_layer.0.bn.bn.bias", [128]], ["rpn_cls_layer.2.conv.weight", [1, 128, 1]], ["rpn_cls_layer.2.conv.bias", [1]], ["rpn_reg_layer.0.conv.weight", [128, 128, 1]], ["rpn_reg_layer.0.bn.bn.weight", [128]], ["rpn_reg_layer.0.bn.bn.bias", [128]], ["rpn_reg_layer.2.conv.weight", [76, 128, 1]], ["rpn_reg_layer.2.conv.bias", [76]]], "output_shape": [[[[0], [0], [0], [0], [0], [0], [0]], [0, 0, 0, 0, 0, [0], [0]], [[0], [0], 0, [0], 0, [0], 0, 0, 0, [0], [0], [0]], [0, 0, 0, 0, 0, 0, 0, 0, 0, [0], 0, 0, [0], [0], 0, 0, 0]]], "num_parameters": [48, 16, 16, 256, 16, 16, 512, 32, 32, 96, 32, 32, 1024, 32, 32, 2048, 64, 64, 6336, 64, 64, 4096, 64, 64, 8192, 128, 128, 6336, 64, 64, 6144, 96, 96, 12288, 128, 128, 33152, 128, 128, 25088, 196, 196, 50176, 256, 256, 33152, 128, 128, 25088, 196, 196, 50176, 256, 256, 131840, 256, 256, 65536, 256, 256, 131072, 512, 512, 131840, 256, 256, 98304, 384, 384, 196608, 512, 512, 32768, 128, 128, 16384, 128, 128, 155648, 256, 256, 65536, 256, 256, 393216, 512, 512, 262144, 512, 512, 786432, 512, 512, 262144, 512, 512, 16384, 128, 128, 128, 1, 16384, 128, 128, 9728, 76]}, {"name": "rcnn_net", "id": 139948149511392, "class_name": "RCNNNet(\n  (SA_modules): ModuleList(\n    (0): PointnetSAModule(\n      (groupers): ModuleList(\n        (0): QueryAndGroup()\n      )\n      (mlps): ModuleList(\n        (0): SharedMLP(\n          (layer0): Conv2d(\n            (conv): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU(inplace)\n          )\n          (layer1): Conv2d(\n            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU(inplace)\n          )\n          (layer2): Conv2d(\n            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU(inplace)\n          )\n        )\n      )\n    )\n    (1): PointnetSAModule(\n      (groupers): ModuleList(\n        (0): QueryAndGroup()\n      )\n      (mlps): ModuleList(\n        (0): SharedMLP(\n          (layer0): Conv2d(\n            (conv): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU(inplace)\n          )\n          (layer1): Conv2d(\n            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU(inplace)\n          )\n          (layer2): Conv2d(\n            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU(inplace)\n          )\n        )\n      )\n    )\n    (2): PointnetSAModule(\n      (groupers): ModuleList(\n        (0): GroupAll()\n      )\n      (mlps): ModuleList(\n        (0): SharedMLP(\n          (layer0): Conv2d(\n            (conv): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU(inplace)\n          )\n          (layer1): Conv2d(\n            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU(inplace)\n          )\n          (layer2): Conv2d(\n            (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU(inplace)\n          )\n        )\n      )\n    )\n  )\n  (xyz_up_layer): SharedMLP(\n    (layer0): Conv2d(\n      (conv): Conv2d(5, 128, kernel_size=(1, 1), stride=(1, 1))\n      (activation): ReLU(inplace)\n    )\n    (layer1): Conv2d(\n      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n      (activation): ReLU(inplace)\n    )\n  )\n  (merge_down_layer): SharedMLP(\n    (layer0): Conv2d(\n      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n      (activation): ReLU(inplace)\n    )\n  )\n  (cls_layer): Sequential(\n    (0): Conv1d(\n      (conv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n      (activation): ReLU(inplace)\n    )\n    (1): Dropout(p=0.0)\n    (2): Conv1d(\n      (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n      (activation): ReLU(inplace)\n    )\n    (3): Conv1d(\n      (conv): Conv1d(256, 1, kernel_size=(1,), stride=(1,))\n    )\n  )\n  (reg_layer): Sequential(\n    (0): Conv1d(\n      (conv): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n      (activation): ReLU(inplace)\n    )\n    (1): Dropout(p=0.0)\n    (2): Conv1d(\n      (conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n      (activation): ReLU(inplace)\n    )\n    (3): Conv1d(\n      (conv): Conv1d(256, 46, kernel_size=(1,), stride=(1,))\n    )\n  )\n  (proposal_target_layer): ProposalTargetLayer()\n)", "parameters": [["SA_modules.0.mlps.0.layer0.conv.weight", [128, 131, 1, 1]], ["SA_modules.0.mlps.0.layer0.conv.bias", [128]], ["SA_modules.0.mlps.0.layer1.conv.weight", [128, 128, 1, 1]], ["SA_modules.0.mlps.0.layer1.conv.bias", [128]], ["SA_modules.0.mlps.0.layer2.conv.weight", [128, 128, 1, 1]], ["SA_modules.0.mlps.0.layer2.conv.bias", [128]], ["SA_modules.1.mlps.0.layer0.conv.weight", [128, 131, 1, 1]], ["SA_modules.1.mlps.0.layer0.conv.bias", [128]], ["SA_modules.1.mlps.0.layer1.conv.weight", [128, 128, 1, 1]], ["SA_modules.1.mlps.0.layer1.conv.bias", [128]], ["SA_modules.1.mlps.0.layer2.conv.weight", [256, 128, 1, 1]], ["SA_modules.1.mlps.0.layer2.conv.bias", [256]], ["SA_modules.2.mlps.0.layer0.conv.weight", [256, 259, 1, 1]], ["SA_modules.2.mlps.0.layer0.conv.bias", [256]], ["SA_modules.2.mlps.0.layer1.conv.weight", [256, 256, 1, 1]], ["SA_modules.2.mlps.0.layer1.conv.bias", [256]], ["SA_modules.2.mlps.0.layer2.conv.weight", [512, 256, 1, 1]], ["SA_modules.2.mlps.0.layer2.conv.bias", [512]], ["xyz_up_layer.layer0.conv.weight", [128, 5, 1, 1]], ["xyz_up_layer.layer0.conv.bias", [128]], ["xyz_up_layer.layer1.conv.weight", [128, 128, 1, 1]], ["xyz_up_layer.layer1.conv.bias", [128]], ["merge_down_layer.layer0.conv.weight", [128, 256, 1, 1]], ["merge_down_layer.layer0.conv.bias", [128]], ["cls_layer.0.conv.weight", [256, 512, 1]], ["cls_layer.0.conv.bias", [256]], ["cls_layer.2.conv.weight", [256, 256, 1]], ["cls_layer.2.conv.bias", [256]], ["cls_layer.3.conv.weight", [1, 256, 1]], ["cls_layer.3.conv.bias", [1]], ["reg_layer.0.conv.weight", [256, 512, 1]], ["reg_layer.0.conv.bias", [256]], ["reg_layer.2.conv.weight", [256, 256, 1]], ["reg_layer.2.conv.bias", [256]], ["reg_layer.3.conv.weight", [46, 256, 1]], ["reg_layer.3.conv.bias", [46]]], "output_shape": [[[[0], [0], [0], 0, [0], 0, [0], [0]], [0, 0, 0, 0, 0, 0, [0], [0]], [0, [0], [0], [0], 0, 0, [0], 0, 0, [0], 0], [0, 0, 0, 0, [0], 0, 0, 0, [0], 0, 0], [0, 0, 0, 0, 0, 0, [0], 0, 0], [0, 0, 0, 0, [0], 0, 0, [0], 0, 0, 0, 0, 0, [0]], [0, 0, 0, [0], 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, [0], 0, 0, [0], 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]]], "num_parameters": [16768, 128, 16384, 128, 16384, 128, 16768, 128, 16384, 128, 32768, 256, 66304, 256, 65536, 256, 131072, 512, 640, 128, 16384, 128, 32768, 128, 131072, 256, 65536, 256, 256, 1, 131072, 256, 65536, 256, 11776, 46]}], "edges": []}